{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core import Workspace, Environment, Datastore, Experiment\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "from azureml.exceptions import WebserviceException\n",
    "from azureml.data.data_reference import DataReference\n",
    "\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import PipelineData, Pipeline\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as jsonfile:\n",
    "    ws_config = json.load(jsonfile)\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=ws_config['tenantId'])\n",
    "\n",
    "ws = Workspace(\n",
    "    subscription_id=ws_config['subscription_id'],\n",
    "    resource_group=ws_config['resource_group'],\n",
    "    workspace_name=ws_config['workspace_name'],\n",
    "    auth=interactive_auth,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "blob_datastore_name='shiftdatastore' # Name of the datastore to workspace\n",
    "container_name=os.getenv(\"BLOB_CONTAINER\", \"news20container\") # Name of Azure blob container\n",
    "account_name=os.getenv(\"BLOB_ACCOUNTNAME\", \"shiftreference\") # Storage account name\n",
    "account_key=os.getenv(\"AZURE_STORAGE_KEY\") # Storage account key\n",
    "\n",
    "try:\n",
    "    datastore = Datastore.get(ws, blob_datastore_name)\n",
    "except:\n",
    "    datastore = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                                             datastore_name=blob_datastore_name, \n",
    "                                                             container_name=container_name, \n",
    "                                                             account_name=account_name,\n",
    "                                                             account_key=account_key)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "blob_input_data = DataReference(\n",
    "    datastore,\n",
    "    data_reference_name=\"rawdata\",\n",
    "    path_on_datastore=\"rawdata\",\n",
    ")\n",
    "\n",
    "# Preprocessed files saved here\n",
    "corpus_output_data = PipelineData(\n",
    "    \"corpus\",\n",
    "    datastore=datastore,\n",
    "    output_path_on_compute=\"corpus\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Found compute target: corpus-compute\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "compute_name = \"corpus-compute\"\n",
    "vm_size = \"STANDARD_D11_V2\"\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('Found compute target: ' + compute_name)\n",
    "else:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,  # STANDARD_NC6 is GPU-enabled\n",
    "                                                                min_nodes=0,\n",
    "                                                                max_nodes=4)\n",
    "    # create the compute target\n",
    "    compute_target = ComputeTarget.create(\n",
    "        ws, compute_name, provisioning_config)\n",
    "\n",
    "    # Can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # If no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    # For a more detailed view of current cluster status, use the 'status' property\n",
    "    print(compute_target.status.serialize())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "env = Environment.from_pip_requirements(\"sbsdeployment\", \"./requirements.txt\")\n",
    "runconfig = RunConfiguration()\n",
    "runconfig.environment = env\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "process_arguments = [\"--input\", blob_input_data, \"--output\", corpus_output_data]\n",
    "process_step = PythonScriptStep(\n",
    "    script_name=\"build_corpus.py\",\n",
    "    arguments=process_arguments,\n",
    "    inputs=[blob_input_data],\n",
    "    outputs=[corpus_output_data],\n",
    "    compute_target=compute_target,\n",
    "    source_directory=os.getcwd(),\n",
    "    runconfig=runconfig,\n",
    "    allow_reuse=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = Pipeline(ws, steps=[process_step])\n",
    "predictions_run = Experiment(ws, \"build_corpus\").submit(predictions)\n",
    "predictions_run.wait_for_completion()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}